# Project: MNIST Dataset with f-GANs

## Description
This project implements **f-GANs** (f-divergence Generative Adversarial Networks) for image generation using the **MNIST dataset**. The goal is to explore and analyze the **precision-recall trade-offs** in generative modeling. The project includes training, evaluation, and visualization of generated images, along with a detailed report and presentation slides.

---

## Table of Contents
1. [Project Overview](#project-overview)
2. [Objectives](#objectives)
3. [Technologies Used](#technologies-used)
4. [Prerequisites](#prerequisites)
5. [Installation](#installation)
6. [Repository Structure](#repository-structure)
7. [Usage](#usage)
8. [Results](#results)
9. [References](#references)
10. [Contributing](#contributing)

---

## Project Overview
The main objective of this project is to generate handwritten digit images using an **f-GAN**. The project involves experimenting with different types of divergences (such as **KL-divergence** and **JS-divergence**) to observe their impact on the quality of generated images and precision-recall trade-offs.

### Key Features:
- Implementation of an **f-GAN** to generate realistic handwritten digits from the MNIST dataset.
- Comparison of various **f-divergences** to assess their impact on image quality.
- Includes a detailed project report and presentation slides.

---

## Objectives
- Develop a generator capable of creating realistic handwritten digit images.
- Test and compare multiple divergences to understand how they affect the diversity and fidelity of generated images.
- Provide a comprehensive analysis of the results in the project report and presentation.

---

## Technologies Used
- **Python** (version 3.8+)
- **PyTorch** (for neural network implementation)
- **Matplotlib** and **Seaborn** (for data visualization)
- **NumPy** and **Pandas** (for data manipulation)

---

## Prerequisites
Before starting, ensure you have the following dependencies installed:
- Python 3.8 or higher
- PyTorch
- Matplotlib
- Seaborn
- NumPy
- Pandas

---

## Installation

### 1. Clone the Repository  
Clone this repository to your local directory using the following command:  
```bash
git clone https://github.com/FChen-Lab/mnist-fgan.git
cd mnist-fgan
```

2. Create a Virtual Environment (Optional but Recommended)
Create a virtual environment:
```bash
python -m venv venv
```

Activate the virtual environment:

On macOS/Linux:

```bash
source venv/bin/activate
```
On Windows:
```bash
venv\Scripts\activate
```
Deactivate the environment when done:

```bash
deactivate
```

3. Install Dependencies
Install all the necessary dependencies using pip:

```bash
pip install -r requirements.txt
```

4. Prepare the Data
The MNIST dataset will be automatically downloaded when running the program. Ensure your internet connection is active during execution.

Repository Structure
Here’s the structure of the files in this repository:
```bash
mnist-fgan/
├── checkpoints/             # Directory for saving trained models
├── README.md                # Project documentation (this file)
├── TrainBIS.py              # Main script for training the f-GAN
├── UtilsBIS.py              # Utility functions for data loading and visualization
├── generate.py              # Script for generating images using the trained model
├── model.py                 # Contains the generator and discriminator models
├── project_report.pdf       # Detailed project report
├── slides_presentation.pdf  # Presentation slides for the project
└── requirements.txt         # List of dependencies
```
Usage
Training the Model
To train the f-GAN model, run the following command:

```bash
python TrainBIS.py --divergence kl --epochs 50 --batch_size 64
```
Arguments:
--divergence: Type of f-divergence to use (e.g., kl, js).

--epochs: Number of training epochs.

--batch_size: Batch size for training.

Generating Images
To generate images using the trained model, run:
```bash
python generate.py --model_path checkpoints/generator.pth --output_dir results/
```
Arguments:
--model_path: Path to the trained generator model.

--output_dir: Directory to save generated images.

Visualizing Results
Use the functions in UtilsBIS.py to visualize results, such as generated images and precision-recall curves.

Results
Generated Images
Sample images generated by the f-GAN can be found in the results/ directory.

Project Report and Presentation
For a detailed analysis of the results, refer to:

Project Report: project_report.pdf

Presentation Slides: slides_presentation.pdf

References
Nowozin, S., Cseke, B., & Tomioka, R. (2016). f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization. Advances in Neural Information Processing Systems (NeurIPS).

Goodfellow, I., et al. (2014). Generative Adversarial Networks. Communications of the ACM.

MNIST Dataset: http://yann.lecun.com/exdb/mnist/

Contributing
Contributions are welcome! If you'd like to contribute, please follow these steps:

Fork the repository.

Create a new branch for your feature or bugfix:
```
git checkout -b feature/your-feature-name
Commit your changes:
```
```bash
git commit -m "Add your commit message here"
Push to the branch:
```
```bash
git push origin feature/your-feature-name
Open a pull request and describe your changes.
```
License: This project is licensed under the MIT License. See the LICENSE file for details.
